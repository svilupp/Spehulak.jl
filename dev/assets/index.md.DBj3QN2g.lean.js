import{_ as t,c as e,o as a,a6 as i}from"./chunks/framework.cK_D0K7G.js";const u=JSON.parse(`{"title":"","description":"","frontmatter":{"layout":"home","hero":{"name":"Spehulak.jl","tagline":"Spy on your LLM conversations","description":"A generative AI observability platform to help you understand what's happening inside your GenAI application.","image":{"src":"https://img.icons8.com/?size=100&id=66415&format=png&color=000000","alt":"Snowman Icon"},"actions":[{"theme":"brand","text":"Introduction","link":"/introduction"},{"theme":"alt","text":"API Reference","link":"/reference"},{"theme":"alt","text":"View on GitHub","link":"https://github.com/svilupp/Spehulak.jl"}]},"features":[{"icon":"<img width=\\"64\\" height=\\"64\\" src=\\"https://img.icons8.com/?size=100&id=46986&format=png&color=000000\\" alt=\\"Integration\\"/>","title":"Integration with PromptingTools","details":"Load serialized LLM conversations and RAG results saved via PromptingTools.jl and inspect them with Spehulak.jl."},{"icon":"<img width=\\"64\\" height=\\"64\\" src=\\"https://img.icons8.com/?size=100&id=46695&format=png&color=000000\\" alt=\\"Navigation\\"/>","title":"Seamless Navigation","details":"Browse through conversations, sample them randomly, filter by keywords, and navigate with ease."},{"icon":"<img width=\\"64\\" height=\\"64\\" src=\\"https://img.icons8.com/?size=100&id=AGmcFT8jaCcR&format=png&color=000000\\" alt=\\"Automatic Replies\\"/>","title":"Metadata Inspection","details":"Inspect granular metadata like prompt template versions, LLM temperature, and models used to gain insights about your GenAI pipelines."}]},"headers":[],"relativePath":"index.md","filePath":"index.md","lastUpdated":null}`),s={name:"index.md"},n=i("",2),o=[n];function l(r,p,h,d,c,m){return a(),e("div",null,o)}const k=t(s,[["render",l]]);export{u as __pageData,k as default};
